

Pipeline structure of MLops Proiject 


1. We creates a template for the whole Project ( folder + files ) using template.py to save time  . 

2. We write some inside info about pckages etc usign setup.py and pyproject.toml ( tom obv minimal lang ) file 

# Anaconda ( conda env ) is liek a DS toolkit that helps us to make DS and AI project much easily . 
like pre-written code (conda make env )  to mae a new env with new packages and new .py versions 

3. We create a new anaconda env for our whoel MLOps project ( mdoel building pipeline -> deployment -> poduction )
( 'conda create -n <env_name python-version  -y'  >)

4. write the list of all modules and packages needed for our project .( and downalod in this new env usign -> 'pip install -r req.txt' ) 


5. activate the NEW env , downalod the modules and start working project ( in  this NEW env ) 

# setup a database on MongoDB ( NO SQL databaase ) from where our pipeline will pull data and train ML mdoel on it an store it 

# uSe of -e . in requiment.txt file at end ? 
# to downlaod local packages ,  we are going to make in out Project ( usign python OOPs ) to be installed correctly 
toolkit
# prewritten python modules , ( works with setup.py ( setup() --> find_packages()  inside src folder ) and 
toml file gives it some extra metadata info.  )

# -e. always requires a setup.py file to isntall OUR pacages as also local packaegs in env 
# so tat all fucntion / obj / classes we make insdie src folder ( will be tretaed as normal mdoule ot packages in env )


6. 
MongoDB atlas ( cloud service ) that helps users to store their non-relational db (json form etc ) online . 
( Organization (company)--> Project --> databases ( clusters on mongodb )--> authrozie networks an db users usign a pasowrd )
and then use this pasword inside a cokection strign to acces the data insid these clsuters ( db) from anywhere . 

MongoDB Org Project cluster DB -> ( username =  polygot882    , password = r9H4CU0CyyRPvZ28  )

connection string to conect with data store din any mongodb clsuter (whuc e have acces to )
mongodb+srv://polygot882:<db_password>@cluster0.evcpkk7.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0

7. Push data from our Notebook to Mongo DB database ( cluster )

using our local PC as a mongo client and definign the Org->Proj -> db -> clsuter->colelction (key-vlaeu pair ) name where we want tp push teh data . 
and using ===>  "collection.insert_many (data.dict )"  to push teh data on mongo db atlas cloud service for org. 


# use of init.py --> helps to use the file and fucntion insid it liek a local pkg (modeue ) -->  frim foldee improt file ( this file rusn __init.py file  as module )

# .gitignore auomcaticlly bu defualt ignores log files and folders 

# diff types of logging msg -> logging , debug , info , warnign ,error , criticla 

# logging file stores the error and msg 

and exception fiel Discretely pin points the exact location where the error located . 
and heps us to debug a aprtifula file at a aprticlat line . 

Thats why , the logging .py + exception.py is very imp 

eg. 

try : 
 a = 1 + 'z' 

 except : 
  raise Ecpetionerro( e ) ---> ( goes to logger file )
  and eception( e ) -- pass to exceptiom fucntion file (and get at Line 2 : addition of str and int NOT possible )

# and THIS HEPS USE IN DEBUGGING of whoel Project 


8. Make a logegr file ( using a __init__.py file ) to store info of logs , erors , or other info imp while afile of the proejct runs 
usign StremaHAndler and sores dat and tim also of tha info and run 